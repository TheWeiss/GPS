{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T08:25:46.711819Z",
     "start_time": "2022-01-31T08:25:42.123588Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import catboost as cb\n",
    "from catboost import Pool\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import ParameterSampler, RandomizedSearchCV\n",
    "from scipy.stats.distributions import expon\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import multiprocessing\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import h2o\n",
    "import tqdm\n",
    "import pickle\n",
    "from autoxgb import AutoXGB\n",
    "from autoxgb.cli.predict import PredictAutoXGBCommand\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "SEED = 42\n",
    "\n",
    "%matplotlib notebook\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T08:25:46.720030Z",
     "start_time": "2022-01-31T08:25:46.715509Z"
    }
   },
   "outputs": [],
   "source": [
    "from autoxgb import AutoXGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T08:25:46.735173Z",
     "start_time": "2022-01-31T08:25:46.722871Z"
    }
   },
   "outputs": [],
   "source": [
    "def look_at_anti_dist(all_ASR, col_name, col_order=None):\n",
    "    col_dist = all_ASR.groupby(by='antibiotic_name')[col_name].apply(lambda x: x.value_counts()).reset_index()\n",
    "    col_dist.columns = ['antibiotic_name', col_name, 'count']\n",
    "    order = col_dist.groupby(by='antibiotic_name')['count'].apply(sum).sort_values().index\n",
    "    col_dist = pd.pivot_table(col_dist, values='count', index=['antibiotic_name'],\n",
    "                    columns=[col_name], aggfunc=np.sum).fillna(0)\n",
    "    if col_order is not None:\n",
    "        col_dist = col_dist[col_order]\n",
    "    ax = col_dist.loc[order].plot.barh(stacked=True, rot=0, figsize=(20,15))\n",
    "    plt.title('Distribution of ' + col_name+' for each anti-biotics')\n",
    "    plt.ylabel('antibiotics')\n",
    "    plt.xlabel('# of measurements')\n",
    "    plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T08:25:46.749299Z",
     "start_time": "2022-01-31T08:25:46.738325Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_anti_measure(all_ASR, anti_index):\n",
    "    anti = all_ASR['antibiotic_name'].value_counts().index[anti_index]\n",
    "    anti_MIC = all_ASR[all_ASR['antibiotic_name'] == anti]\n",
    "    anti_MIC['measurement'] = anti_MIC['measurement'].apply(np.log2)\n",
    "    low = anti_MIC['measurement'].min().round()\n",
    "    high = anti_MIC['measurement'].max().round()\n",
    "    hist_range = np.arange(low-0.5, high+1, 1)\n",
    "    bins_count = pd.DataFrame(anti_MIC.groupby(by='measurement_sign')['measurement'].apply(lambda x: np.histogram(x, bins=hist_range)[0]))\n",
    "    bins_count = bins_count.merge(pd.DataFrame({'fill': [np.zeros(len(hist_range)-1)]}, index=['=', '<=', '>=', '<', '>']), left_index=True, right_index=True, how='right')\n",
    "    bins_count['measurement'].fillna(bins_count['fill'], inplace=True)\n",
    "    pd.DataFrame(bins_count['measurement'].tolist(), index= bins_count.index, columns=hist_range[:-1]+0.5).T.plot.bar(stacked=True)\n",
    "    plt.title(anti)\n",
    "    plt.xlabel('log2(mg//L)')\n",
    "    plt.ylabel('#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T08:25:46.772240Z",
     "start_time": "2022-01-31T08:25:46.751445Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_filtered_data(\n",
    "    data = 'tot_filtered_data.csv', \n",
    "    features = 'final_features',\n",
    "    ASR_data = 'filtered_ASR_data.csv', \n",
    "    species_sep = True, \n",
    "    species_filter_index=0, \n",
    "    naive=True, \n",
    "    test_range=False, \n",
    "    antibiotic_index=0,\n",
    "    task='regression', \n",
    "    strip_range_train=False,\n",
    "    distance_range_train=False,\n",
    "    range_moved=5,\n",
    "):\n",
    "    data = pd.read_csv('../resources/'+data)\n",
    "    with open(\"../resources/\"+ features, \"rb\") as fp:\n",
    "        features = pickle.load(fp)\n",
    "    ASR_data = pd.read_csv('../resources/'+ASR_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    species2merge = data[['biosample_id', 'species_fam']]\n",
    "    filtered_ASR = ASR_data.drop('species_fam', axis=1).merge(species2merge, on='biosample_id')\n",
    "    filtered_ASR.set_index('biosample_id', inplace=True)\n",
    "    filtered_ASR = filtered_ASR[filtered_ASR['units']=='mg/L']\n",
    "    filtered_ASR = filtered_ASR[filtered_ASR['ast_standard']=='CLSI']\n",
    "    filtered_ASR = filtered_ASR[filtered_ASR['species_fam']!='senterica']\n",
    "    filtered_ASR = filtered_ASR[filtered_ASR['species_fam']!='spneumoniae']\n",
    "    data.set_index('biosample_id', inplace=True)\n",
    "    data.drop(['Unnamed: 0', 'species_fam', 'run_id'], axis=1, inplace=True)\n",
    "            \n",
    "    if species_sep:\n",
    "        species = filtered_ASR['species_fam'].value_counts().reset_index()['index'].iloc[species_filter_index]\n",
    "        filtered_ASR = filtered_ASR[filtered_ASR['species_fam'] == species]\n",
    "    else:\n",
    "        species = None\n",
    "    \n",
    "    if test_range:\n",
    "        test_ASR = filtered_ASR[filtered_ASR['measurement_sign']!='=']    \n",
    "        \n",
    "    if naive:\n",
    "        filtered_ASR = filtered_ASR[filtered_ASR['measurement_sign']=='=']\n",
    "    \n",
    "    anti_list = filtered_ASR['antibiotic_name'].value_counts().index.values\n",
    "    label = anti_list[antibiotic_index]\n",
    "    \n",
    "    y = data.loc[filtered_ASR[filtered_ASR['antibiotic_name'] == label].index][label]\n",
    "    \n",
    "    if naive:\n",
    "        if task == 'regression':\n",
    "            y = y.apply(lambda x: float(x.split(' ')[1]))\n",
    "        elif task == 'classification':\n",
    "            y = y.apply(lambda x: str(x.split(' ')[1]))\n",
    "            \n",
    "    else:\n",
    "        if task == 'classification':\n",
    "            y=y\n",
    "        elif task == 'regression':\n",
    "            if strip_range_train:\n",
    "                y = y.apply(lambda x: float(x.split(' ')[1]))\n",
    "            elif distance_range_train:\n",
    "                signs = y.apply(lambda x: str(x.split(' ')[0]))\n",
    "                y = y.apply(lambda x: float(x.split(' ')[1]))\n",
    "                \n",
    "            else:\n",
    "                print('regression not in the naive approach is not implemented yet.') \n",
    "        \n",
    "            \n",
    "    \n",
    "    if test_range:\n",
    "        range_test_values = data.loc[test_ASR[test_ASR['antibiotic_name'] == label].index][label]\n",
    "        range_labels = pd.DataFrame({\n",
    "            'values':[],\n",
    "            'direction': [],\n",
    "        })\n",
    "        range_labels['values'] = range_test_values.apply(lambda x: float(x.split(' ')[1]))\n",
    "        range_labels['direction'] = range_test_values.apply(lambda x: x.split(' ')[0].replace('=', ''))\n",
    "    else:\n",
    "        range_labels = None\n",
    "        X_range = None\n",
    "        \n",
    "    \n",
    "    X = data.loc[filtered_ASR[filtered_ASR['antibiotic_name'] == label].index][features]\n",
    "    X.dropna(axis=1, how='all', inplace=True)\n",
    "    X.fillna(0, inplace=True)\n",
    "    \n",
    "    if test_range:\n",
    "        train_features = X.columns.values\n",
    "        X_range = data.loc[test_ASR[test_ASR['antibiotic_name'] == label].index][train_features]\n",
    "        X_range.fillna(0, inplace=True)\n",
    "    \n",
    "    return X, y, X_range, range_labels, list(train_features), label, species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_data_multi_anti(\n",
    "    data = 'tot_filtered_data.csv', \n",
    "    features = 'final_features',\n",
    "    ASR_data = 'filtered_ASR_data.csv', \n",
    "    species_sep = True, \n",
    "    species_filter_index=0, \n",
    "    naive=True, \n",
    "    test_range=False, \n",
    "    task='regression', \n",
    "    strip_range_train=False,\n",
    "    distance_range_train=False,\n",
    "    range_moved=5,\n",
    "    filter_antibiotics_size = 30,\n",
    "):\n",
    "    data = pd.read_csv('../resources/'+'tot_filtered_data.csv')\n",
    "    with open(\"../resources/\"+ 'final_features', \"rb\") as fp:\n",
    "        features = pickle.load(fp)\n",
    "    ASR_data = pd.read_csv('../resources/'+'filtered_ASR_data.csv')\n",
    "\n",
    "\n",
    "\n",
    "    species2merge = data[['biosample_id', 'species_fam']]\n",
    "    filtered_ASR = ASR_data.drop('species_fam', axis=1).merge(species2merge, on='biosample_id')\n",
    "    filtered_ASR.set_index('biosample_id', inplace=True)\n",
    "    filtered_ASR = filtered_ASR[filtered_ASR['units']=='mg/L']\n",
    "    filtered_ASR = filtered_ASR[filtered_ASR['ast_standard']=='CLSI']\n",
    "    filtered_ASR = filtered_ASR[filtered_ASR['species_fam']!='senterica']\n",
    "    filtered_ASR = filtered_ASR[filtered_ASR['species_fam']!='spneumoniae']\n",
    "    data.set_index('biosample_id', inplace=True)\n",
    "    data.drop(['Unnamed: 0', 'species_fam', 'run_id'], axis=1, inplace=True)\n",
    "\n",
    "    if species_sep:\n",
    "        species = filtered_ASR['species_fam'].value_counts().reset_index()['index'].iloc[species_filter_index]\n",
    "        filtered_ASR = filtered_ASR[filtered_ASR['species_fam'] == species]\n",
    "    else:\n",
    "        species = None\n",
    "\n",
    "    if test_range:\n",
    "        test_ASR = filtered_ASR[filtered_ASR['measurement_sign']!='=']    \n",
    "\n",
    "    if naive:\n",
    "        filtered_ASR = filtered_ASR[filtered_ASR['measurement_sign']=='=']\n",
    "\n",
    "    anti_list = filtered_ASR['antibiotic_name'].value_counts()[filtered_ASR['antibiotic_name'].value_counts() > filter_antibiotics_size].index.values\n",
    "    filtered_ASR = filtered_ASR[filtered_ASR['antibiotic_name'].apply(lambda x: x in anti_list)]\n",
    "    filtered_ASR = filtered_ASR.reset_index().set_index(['biosample_id', 'antibiotic_name']).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "    if test_range:\n",
    "        test_ASR = test_ASR[test_ASR['antibiotic_name'].apply(lambda x: x in anti_list)]\n",
    "        test_ASR = test_ASR.reset_index().set_index(['biosample_id', 'antibiotic_name']).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "    data = data.melt(\n",
    "        id_vars=features,\n",
    "        ignore_index=False,\n",
    "        value_vars=anti_list,\n",
    "        var_name='antibiotic_name',\n",
    "        value_name='measurement',\n",
    "    ).dropna(axis=0, subset=['measurement'])\n",
    "\n",
    "    data = data.reset_index().set_index(['biosample_id', 'antibiotic_name'])\n",
    "    label = 'measurement'\n",
    "    y = data.loc[filtered_ASR.index]['measurement']\n",
    "\n",
    "    if naive:\n",
    "        if task == 'regression':\n",
    "            y = y.apply(lambda x: float(x.split(' ')[1]))\n",
    "        elif task == 'classification':\n",
    "            y = y.apply(lambda x: str(x.split(' ')[1]))\n",
    "    else:\n",
    "        if task == 'classification':\n",
    "            y=y\n",
    "        elif task == 'regression':\n",
    "            if strip_range_train:\n",
    "                y = y.apply(lambda x: float(x.split(' ')[1]))\n",
    "            elif distance_range_train:\n",
    "                signs = y.apply(lambda x: str(x.split(' ')[0]))\n",
    "                y = y.apply(lambda x: float(x.split(' ')[1]))\n",
    "\n",
    "            else:\n",
    "                print('regression not in the naive approach is not implemented yet.') \n",
    "\n",
    "\n",
    "    if test_range:\n",
    "        range_test_values = data.loc[test_ASR.index]['measurement']\n",
    "        range_labels = pd.DataFrame({\n",
    "            'values':[],\n",
    "            'direction': [],\n",
    "        })\n",
    "        range_labels['values'] = range_test_values.apply(lambda x: float(x.split(' ')[1]))\n",
    "        range_labels['direction'] = range_test_values.apply(lambda x: x.split(' ')[0].replace('=', ''))\n",
    "    else:\n",
    "        range_labels = None\n",
    "        X_range = None\n",
    "\n",
    "\n",
    "    X = data.loc[filtered_ASR.index][features]\n",
    "    X.dropna(axis=1, how='all', inplace=True)\n",
    "    X.fillna(0, inplace=True)\n",
    "\n",
    "    if test_range:\n",
    "        train_features = X.columns.values\n",
    "        X_range = data.loc[test_ASR.index][train_features]\n",
    "        X_range.fillna(0, inplace=True)\n",
    "        X_range = X_range.reset_index().set_index('biosample_id')\n",
    "    \n",
    "    train_id, test_id = train_test_split(list(set(y.index.get_level_values(0).values)), test_size=0.2, random_state=42)\n",
    "    X_train = X.loc[train_id,].reset_index().set_index('biosample_id')\n",
    "    X_test = X.loc[test_id,].reset_index().set_index('biosample_id')\n",
    "    y_train = y.loc[train_id,].reset_index().set_index('biosample_id')\n",
    "    y_test = y.loc[test_id,].reset_index().set_index('biosample_id')\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, X_range, range_labels, list(train_features)+['antibiotic_name'], label, species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    X_train, y_train, X_test, y_test, X_range, y_range, features, label, species = get_filtered_data_multi_anti(\n",
    "        data = 'tot_filtered_data.csv', \n",
    "        features = 'final_features',\n",
    "        ASR_data = 'filtered_ASR_data.csv', \n",
    "        species_sep = True, \n",
    "        species_filter_index=species_filter_index, \n",
    "        naive=naive, \n",
    "        strip_range_train=strip_range_train,\n",
    "        test_range=test_range, \n",
    "        task='regression',\n",
    "    )\n",
    "    # X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train['measurement'])\n",
    "    # X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test['measurement'])\n",
    "    \n",
    "    categorical_features_indices = np.where(X_train.dtypes != np.float)[0]\n",
    "    train_pool = Pool(X_train, y_train, cat_features=categorical_features_indices)\n",
    "    test_pool = Pool(X_test, y_test, cat_features=categorical_features_indices)\n",
    "    # Parameters\n",
    "    params = set_param(trial)\n",
    "    # Learning\n",
    "    \n",
    "    model = cb.CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        eval_metric=\"RMSE\",\n",
    "        task_type=\"GPU\",\n",
    "        l2_leaf_reg=50,\n",
    "        random_seed=SEED,\n",
    "        border_count=64,\n",
    "        cat_features = categorical_features_indices,\n",
    "        **params\n",
    "    )\n",
    "    model.set_feature_names(features)\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=test_pool,\n",
    "        use_best_model=True,\n",
    "        verbose=500,\n",
    "        plot=False,\n",
    "    )\n",
    "    # Predict\n",
    "    preds = model.predict(test_pool)\n",
    "    y_pred = np.rint(preds)\n",
    "    \n",
    "    # Evaluation\n",
    "    rmse_test = mse(y_test, preds, squared=False)\n",
    "    rmse_r_test = mse(y_test, y_pred, squared=False)\n",
    "    print('rmse Score of CatBoost =', rmse_test)\n",
    "    print('rounded rmse Score of CatBoost =', rmse_r_test)\n",
    "    return rmse_r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best(trial, exp_name):\n",
    "    # Use same code objective to reproduce the best model\n",
    "    X_train, y_train, X_test, y_test, X_range, y_range, features, label, species = get_filtered_data_multi_anti(\n",
    "        data = 'tot_filtered_data.csv', \n",
    "        features = 'final_features',\n",
    "        ASR_data = 'filtered_ASR_data.csv', \n",
    "        species_sep = True, \n",
    "        species_filter_index=species_filter_index, \n",
    "        naive=naive, \n",
    "        strip_range_train=strip_range_train,\n",
    "        test_range=test_range, \n",
    "        task='regression',\n",
    "    )\n",
    "    \n",
    "    categorical_features_indices = np.where(X_train.dtypes != np.float)[0]\n",
    "    train_pool = Pool(X_train, np.array(y_train['measurement']), cat_features=categorical_features_indices)\n",
    "    test_pool = Pool(X_test, np.array(y_test['measurement']), cat_features=categorical_features_indices)\n",
    "    range_pool = Pool(X_range, np.array(y_range['values']), cat_features=categorical_features_indices)\n",
    "    \n",
    "    # Parameters\n",
    "    params = set_param(trial)\n",
    "    # Learning\n",
    "    model = cb.CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        eval_metric=\"RMSE\",\n",
    "        task_type=\"GPU\",\n",
    "        l2_leaf_reg=50,\n",
    "        random_seed=SEED,\n",
    "        border_count=64,\n",
    "        cat_features = categorical_features_indices,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    # calculate more evaluation metrics\n",
    "    model.set_feature_names(features)\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=test_pool,\n",
    "        use_best_model=True,\n",
    "        verbose=500,\n",
    "        plot=False,\n",
    "    )\n",
    "    pickle.dump(params, open('../experiments/{}/CatBoost_Hyperparameter.pickle'.format(exp_name), 'wb'))\n",
    "    \n",
    "    # Predict\n",
    "    train_preds = model.predict(train_pool)\n",
    "    pickle.dump(train_preds, open('../experiments/{}/train_pred.pickle'.format(exp_name), 'wb'))\n",
    "    pickle.dump(y_train, open('../experiments/{}/train_y.pickle'.format(exp_name), 'wb'))\n",
    "    \n",
    "    preds = model.predict(test_pool)\n",
    "    pickle.dump(preds, open('../experiments/{}/test_pred.pickle'.format(exp_name), 'wb'))\n",
    "    pickle.dump(y_test, open('../experiments/{}/test_y.pickle'.format(exp_name), 'wb'))\n",
    "    y_pred = np.rint(preds)\n",
    "\n",
    "    if test_range:\n",
    "        range_pred = model.predict(range_pool)\n",
    "        pickle.dump(range_pred, open('../experiments/{}/range_pred.pickle'.format(exp_name), 'wb'))\n",
    "        pickle.dump(y_range, open('../experiments/{}/range_y.pickle'.format(exp_name), 'wb'))\n",
    "        \n",
    "    rmse_test = mse(np.array(y_test['measurement']), preds, squared=False)\n",
    "    rmse_r_test = mse(np.array(y_test['measurement']), y_pred, squared=False)\n",
    "        \n",
    "    return rmse_test, rmse_r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_filter_index_list = [0]\n",
    "naive = False\n",
    "strip_range_train=False\n",
    "train_time = 60\n",
    "test_range=True\n",
    "distance_range_train=True\n",
    "range_moved=5\n",
    "exp_describtion = 'range_distanced_by{}'.format(range_moved)\n",
    "n_trials = 1000\n",
    "def set_param(trial):\n",
    "    return {\n",
    "        'iterations' : trial.suggest_int('iterations', 1000, 10000),                                              \n",
    "        'depth' : trial.suggest_int('depth', 4, 10),                                                    \n",
    "        'random_strength' :trial.suggest_int('random_strength', 0, 100),                       \n",
    "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "        'learning_rate' :trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amitdanw/.conda/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:14: DtypeWarning: Columns (17,18,19,20,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/amitdanw/.conda/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:14: DtypeWarning: Columns (2,5,6,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "\u001b[32m[I 2022-03-09 00:27:27,473]\u001b[0m A new study created in memory with name: no-name-b1851624-c472-41e1-bbd0-e22a04479b68\u001b[0m\n",
      "/home/amitdanw/.conda/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:11: DtypeWarning: Columns (17,18,19,20,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/amitdanw/.conda/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:11: DtypeWarning: Columns (2,5,6,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression not in the naive approach is not implemented yet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amitdanw/.conda/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\u001b[33m[W 2022-03-09 00:27:31,337]\u001b[0m Trial 0 failed because of the following error: CatBoostError('catboost/private/libs/target/target_converter.cpp:35: Target value \">= 6.0\" cannot be parsed as float')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amitdanw/.conda/envs/myenv/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1995/3355920613.py\", line 41, in objective\n",
      "    plot=False,\n",
      "  File \"/home/amitdanw/.conda/envs/myenv/lib/python3.7/site-packages/catboost/core.py\", line 5302, in fit\n",
      "    save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "  File \"/home/amitdanw/.conda/envs/myenv/lib/python3.7/site-packages/catboost/core.py\", line 2042, in _fit\n",
      "    train_params[\"init_model\"]\n",
      "  File \"/home/amitdanw/.conda/envs/myenv/lib/python3.7/site-packages/catboost/core.py\", line 1464, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4393, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4442, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/private/libs/target/target_converter.cpp:35: Target value \">= 6.0\" cannot be parsed as float\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/private/libs/target/target_converter.cpp:35: Target value \">= 6.0\" cannot be parsed as float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1995/3900427438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../experiments/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#multiprocessing.cpu_count())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mevaluate_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CatBoost Hyperparameter:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1995/3355920613.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0muse_best_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5300\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5301\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5302\u001b[0;31m                          save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0m\u001b[1;32m   5303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2043\u001b[0m             )\n\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: catboost/private/libs/target/target_converter.cpp:35: Target value \">= 6.0\" cannot be parsed as float"
     ]
    }
   ],
   "source": [
    "studies = []\n",
    "for species_filter_index in species_filter_index_list:\n",
    "    X_train, y_train, X_test, y_test, X_range, y_range, features, label, species = get_filtered_data_multi_anti(\n",
    "        data = 'tot_filtered_data.csv', \n",
    "        features = 'final_features',\n",
    "        ASR_data = 'filtered_ASR_data.csv', \n",
    "        species_sep = True, \n",
    "        species_filter_index=species_filter_index, \n",
    "        naive=naive, \n",
    "        strip_range_train=strip_range_train,\n",
    "        distance_range_train=distance_range_train,\n",
    "        range_moved=range_moved,\n",
    "        test_range=test_range, \n",
    "        task='regression',\n",
    "    )\n",
    "    exp_name = '{}_{}_for_{}_trials'.format(species, exp_describtion, n_trials)\n",
    "    os.makedirs('../experiments/{}'.format(exp_name), exist_ok=True)\n",
    "    study = optuna.create_study(direction = \"minimize\", sampler = TPESampler(seed=int(SEED)))\n",
    "    study.optimize(objective, n_trials = n_trials, n_jobs = 1)#multiprocessing.cpu_count())\n",
    "    evaluate_best(study.best_trial, exp_name)\n",
    "    print('CatBoost Hyperparameter:', study.best_trial.params)\n",
    "    studies.append(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## playing with autoxgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for species_filter_index in species_filter_index_list:\n",
    "    train, test, X_range, y_range, features, label, species = get_filtered_data_multi_anti(\n",
    "        data = 'tot_filtered_data.csv', \n",
    "        features = 'final_features',\n",
    "        ASR_data = 'filtered_ASR_data.csv', \n",
    "        species_sep = True, \n",
    "        species_filter_index=species_filter_index, \n",
    "        naive=naive, \n",
    "        strip_range_train=strip_range_train,\n",
    "        test_range=test_range, \n",
    "        task='regression',\n",
    "    )\n",
    "    exp_name = '{}_{}_for_{}_min'.format(species, exp_describtion, train_time/60)\n",
    "    train.to_csv('../resources/train_{}.csv'.format(exp_name))\n",
    "    test.to_csv('../resources/test_{}.csv'.format(exp_name))\n",
    "    X_range.to_csv('../resources/range_{}.csv'.format(exp_name))\n",
    "    y_range.to_csv('../resources/y_range_{}.csv'.format(exp_name))\n",
    "    pd.DataFrame({'features': features}).to_csv('../resources/features_{}.csv'.format(exp_name))\n",
    "    pd.DataFrame({'label': [label]}).to_csv('../resources/label_{}.csv'.format(exp_name))\n",
    "\n",
    "    # required parameters:\n",
    "    train_filename = '../resources/train_{}.csv'.format(exp_name)\n",
    "    output = '../experiments/{}'.format(exp_name)\n",
    "\n",
    "    # optional parameters\n",
    "    test_filename = '../resources/test_{}.csv'.format(exp_name)\n",
    "    task = 'regression'\n",
    "    idx = 'biosample_id'\n",
    "    targets = [label]\n",
    "    features = features\n",
    "    categorical_features = None\n",
    "    use_gpu = True\n",
    "    num_folds = 5\n",
    "    seed = 42\n",
    "    num_trials = 100\n",
    "    time_limit = train_time\n",
    "    fast = False\n",
    "\n",
    "    # Now its time to train the model!\n",
    "    axgb = AutoXGB(\n",
    "        train_filename=train_filename,\n",
    "        output=output,\n",
    "        test_filename=test_filename,\n",
    "        task=task,\n",
    "        idx=idx,\n",
    "        targets=targets,\n",
    "        features=features,\n",
    "        categorical_features=None,\n",
    "        use_gpu=use_gpu,\n",
    "        num_folds=num_folds,\n",
    "        seed=seed,\n",
    "        num_trials=num_trials,\n",
    "        time_limit=time_limit,\n",
    "        fast=fast,\n",
    "    )\n",
    "    axgb.train()\n",
    "    if test_range:\n",
    "        PredictAutoXGBCommand('../experiments/{}'.format(exp_name), '../resources/range_{}.csv'.format(exp_name), '../experiments/{}/range_preds.csv'.format(exp_name)).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T13:08:54.489761Z",
     "start_time": "2022-01-25T12:13:03.755837Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# required parameters:\n",
    "train_filename = '../resources/train_{}.csv'.format(exp_name)\n",
    "output = exp_name\n",
    "\n",
    "# optional parameters\n",
    "test_filename = '../resources/test_{}.csv'.format(exp_name)\n",
    "task = 'regression'\n",
    "idx = 'unique_id'\n",
    "targets = [y.name]\n",
    "features = list(X.columns.values)\n",
    "categorical_features = None\n",
    "use_gpu = True\n",
    "num_folds = 5\n",
    "seed = 42\n",
    "num_trials = 100\n",
    "time_limit = 3600\n",
    "fast = False\n",
    "\n",
    "# Now its time to train the model!\n",
    "axgb = AutoXGB(\n",
    "    train_filename=train_filename,\n",
    "    output=output,\n",
    "    test_filename=test_filename,\n",
    "    task=task,\n",
    "    idx=idx,\n",
    "    targets=targets,\n",
    "    features=features,\n",
    "    categorical_features=categorical_features,\n",
    "    use_gpu=use_gpu,\n",
    "    num_folds=num_folds,\n",
    "    seed=seed,\n",
    "    num_trials=num_trials,\n",
    "    time_limit=time_limit,\n",
    "    fast=fast,\n",
    ")\n",
    "axgb.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T13:24:27.971530Z",
     "start_time": "2022-01-25T13:24:27.349452Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PredictAutoXGBCommand(exp_name, '../resources/range_{}.csv'.format(exp_name), '{}/range_preds.csv'.format(exp_name)).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### exact results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T11:23:27.881799Z",
     "start_time": "2022-01-25T11:23:27.878549Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# exp_name = 'largest_species_and_anti_train_striped_range_60min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:03:31.194893Z",
     "start_time": "2022-01-25T14:03:31.179495Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label = pd.read_csv('../resources/label_{}.csv'.format(exp_name)).loc[0, 'label']\n",
    "y_range = pd.read_csv('../resources/y_range_{}.csv'.format(exp_name)).set_index('unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:03:31.458350Z",
     "start_time": "2022-01-25T14:03:31.409070Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('../resources/train_{}.csv'.format(exp_name)).set_index('unique_id')[label]\n",
    "train_res = pd.read_csv('../notebooks/{}/oof_predictions.csv'.format(exp_name)).set_index('unique_id').merge(y, left_index=True, right_index=True, how='inner')\n",
    "train_res = train_res.loc[set(train_res.index)-set(y_range.index)]\n",
    "train_res.columns=['y_pred', 'y_true']\n",
    "train_res['y_true'] = np.round(train_res['y_true'])\n",
    "min_true = train_res['y_true'].min()\n",
    "max_true = train_res['y_true'].max(axis=0)\n",
    "train_res['y_pred'] = train_res['y_pred'].clip(lower=min_true, upper=max_true)\n",
    "train_res['residual'] = train_res['y_true'] - train_res['y_pred']\n",
    "train_res['y_pred'] = np.round(train_res['y_pred'])\n",
    "train_res['round_residual'] = train_res['y_true'] - train_res['y_pred']\n",
    "train_res.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:03:31.893242Z",
     "start_time": "2022-01-25T14:03:31.837494Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('../resources/test_{}.csv'.format(exp_name)).set_index('unique_id')[label]\n",
    "test_res = pd.read_csv('../notebooks/{}/test_predictions.csv'.format(exp_name)).set_index('unique_id').merge(y, left_index=True, right_index=True, how='inner')\n",
    "test_res = test_res.loc[set(test_res.index)-set(y_range.index)]\n",
    "test_res.columns=['y_pred', 'y_true']\n",
    "test_res['y_true'] = np.round(test_res['y_true'])\n",
    "min_true = test_res['y_true'].min()\n",
    "max_true = test_res['y_true'].max(axis=0)\n",
    "test_res['y_pred'] = test_res['y_pred'].clip(lower=min_true, upper=max_true)\n",
    "test_res['residual'] = test_res['y_true'] - test_res['y_pred']\n",
    "test_res['y_pred'] = np.round(test_res['y_pred'])\n",
    "test_res['round_residual'] = test_res['y_true'] - test_res['y_pred']\n",
    "test_res.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:03:33.198979Z",
     "start_time": "2022-01-25T14:03:33.187379Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, res in {'Train': train_res, 'Test': test_res}.items():\n",
    "    print(key)\n",
    "    print('RMSE: {}'.format(res['residual'].std()))\n",
    "    print('RMSE after rounding: {}'.format(res['round_residual'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:03:33.986082Z",
     "start_time": "2022-01-25T14:03:33.978063Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "regression_res = pd.DataFrame({\n",
    "    'exact RMSE': [train_res['residual'].std(), test_res['residual'].std()],\n",
    "    'exact_rounded RMSE': [train_res['round_residual'].std(), test_res['round_residual'].std()],\n",
    "}, index=['train', 'test'])\n",
    "regression_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:04:00.933119Z",
     "start_time": "2022-01-25T14:03:59.697015Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, res in {'Train': train_res, 'Test': test_res}.items():\n",
    "    titles_options = [\n",
    "        (key+ \" Confusion matrix, without normalization\", None),\n",
    "        (key+\" Normalized confusion matrix\", \"true\"),\n",
    "    ]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = ConfusionMatrixDisplay.from_predictions(\n",
    "            np.round(res['y_true']),\n",
    "            res['y_pred'],\n",
    "            labels=np.sort(list(set(list(np.round(res['y_true']).unique())).union(set(list(np.round(res['y_pred']).unique()))))),\n",
    "    #         display_labels=np.sort(list(train_res['y_true'].unique())),\n",
    "            cmap=plt.cm.Blues,\n",
    "            normalize=normalize,\n",
    "        )\n",
    "        disp.ax_.set_title(title)\n",
    "        cm = pd.DataFrame(disp.confusion_matrix, index=disp.display_labels, columns=disp.display_labels)\n",
    "        cm.columns.name='predicted_labels'\n",
    "        cm.index.name='true_labels'\n",
    "        cm.to_csv('../notebooks/{}/{}_df_confusion_matrix_{}.csv'.format(exp_name, key, normalize))\n",
    "        plt.savefig('../notebooks/{}/{}_confusion_matrix_{}.png'.format(exp_name, key, normalize), format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### range result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:18:09.968581Z",
     "start_time": "2022-01-25T14:18:09.965375Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "equal_meaning = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:18:11.105573Z",
     "start_time": "2022-01-25T14:18:11.058169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "range_res = pd.read_csv('../notebooks/{}/range_preds.csv'.format(exp_name)).set_index('unique_id').merge(y_range, left_index=True, right_index=True, how='inner')\n",
    "range_res.columns=['y_pred'] + list(range_res.columns.values)[1:]\n",
    "range_res['values'] = np.round(range_res['values'])\n",
    "range_res['updated_values'] = np.nan\n",
    "range_res['updated_direction'] = np.nan\n",
    "if equal_meaning:\n",
    "        range_res.loc[range_res['direction'] == '>=','updated_values'] = range_res['values'] - 1\n",
    "        range_res.loc[range_res['direction'] == '<=','updated_values'] = range_res['values'] + 1\n",
    "range_res.loc[range_res['direction'] == '>=','updated_direction'] = '>'\n",
    "range_res.loc[range_res['direction'] == '<=','updated_direction'] = '<'\n",
    "\n",
    "range_res.loc[:,'updated_values'].fillna(range_res['values'], inplace=True)\n",
    "range_res.loc[:,'updated_direction'].fillna(range_res['direction'], inplace=True)\n",
    "\n",
    "range_res.loc[range_res['updated_direction'] == '>','answer'] = (range_res['y_pred'] > range_res['updated_values'])\n",
    "range_res.loc[range_res['updated_direction'] == '<','answer'] = (range_res['y_pred'] < range_res['updated_values'])\n",
    "train_range_res = range_res.loc[set(range_res.index).intersection(set(train.index))]\n",
    "test_range_res = range_res.loc[set(range_res.index) - set(train.index)]\n",
    "for key, res in {'train': train_range_res, 'test': test_range_res}.items():\n",
    "    range_confusion = res.groupby(by=['direction', 'values'])['answer'].agg(['count', 'sum']).replace(True, 1)\n",
    "    range_confusion['perc'] = range_confusion['sum'] / range_confusion['count']\n",
    "    range_confusion.columns = ['total', 'in range', 'accuracy']\n",
    "    range_confusion = pd.DataFrame(range_confusion.stack()).T.swaplevel(i=2, j=0, axis=1)\n",
    "    range_confusion.index=[key]\n",
    "    regression_res = pd.concat([regression_res, range_confusion], axis=1)\n",
    "regression_res_cleaned = pd.DataFrame({})\n",
    "for col in regression_res.columns:\n",
    "    if len(regression_res[[col]].columns) > 1:\n",
    "        regression_res_cleaned[col] = regression_res[[col]].iloc[:,0].fillna(regression_res[[col]].iloc[:,1])\n",
    "    else:\n",
    "        regression_res_cleaned[col] = regression_res[[col]]\n",
    "regression_res = regression_res_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:18:17.776531Z",
     "start_time": "2022-01-25T14:18:17.761853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "regression_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:18:33.047023Z",
     "start_time": "2022-01-25T14:18:33.038257Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "regression_res.to_csv('../notebooks/{}/df_regression_results.csv'.format(exp_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T12:04:51.117524Z",
     "start_time": "2022-01-25T12:04:51.114029Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Playing with h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T21:23:57.761688Z",
     "start_time": "2022-01-24T21:23:57.711125Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T23:09:25.669006Z",
     "start_time": "2022-01-24T21:23:58.260315Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# Start the H2O cluster (locally)\n",
    "h2o.init()\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "trainH2o = h2o.import_file('../resources/train_{}.csv'.format(exp_name))\n",
    "testH2o = h2o.import_file('../resources/test_{}.csv'.format(exp_name))\n",
    "\n",
    "# Identify predictors and response\n",
    "x = features\n",
    "y = label\n",
    "\n",
    "# Run AutoML for 20 base models\n",
    "aml = H2OAutoML(max_models=100, seed=1, max_runtime_secs=86400)\n",
    "aml.train(x=x, y=y, training_frame=trainH2o)\n",
    "\n",
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)\n",
    "\n",
    "# model_id                                                  auc    logloss    mean_per_class_error      rmse       mse\n",
    "# ---------------------------------------------------  --------  ---------  ----------------------  --------  --------\n",
    "# StackedEnsemble_AllModels_AutoML_20181212_105540     0.789801   0.551109                0.333174  0.43211   0.186719\n",
    "# StackedEnsemble_BestOfFamily_AutoML_20181212_105540  0.788425   0.552145                0.323192  0.432625  0.187165\n",
    "# XGBoost_1_AutoML_20181212_105540                     0.784651   0.55753                 0.325471  0.434949  0.189181\n",
    "# XGBoost_grid_1_AutoML_20181212_105540_model_4        0.783523   0.557854                0.318819  0.435249  0.189441\n",
    "# XGBoost_grid_1_AutoML_20181212_105540_model_3        0.783004   0.559613                0.325081  0.435708  0.189841\n",
    "# XGBoost_2_AutoML_20181212_105540                     0.78136    0.55888                 0.347074  0.435907  0.190015\n",
    "# XGBoost_3_AutoML_20181212_105540                     0.780847   0.559589                0.330739  0.43613   0.190209\n",
    "# GBM_5_AutoML_20181212_105540                         0.780837   0.559903                0.340848  0.436191  0.190263\n",
    "# GBM_2_AutoML_20181212_105540                         0.780036   0.559806                0.339926  0.436415  0.190458\n",
    "# GBM_1_AutoML_20181212_105540                         0.779827   0.560857                0.335096  0.436616  0.190633\n",
    "# GBM_3_AutoML_20181212_105540                         0.778669   0.56179                 0.325538  0.437189  0.191134\n",
    "# XGBoost_grid_1_AutoML_20181212_105540_model_2        0.774411   0.575017                0.322811  0.4427    0.195984\n",
    "# GBM_4_AutoML_20181212_105540                         0.771426   0.569712                0.33742   0.44107   0.194543\n",
    "# GBM_grid_1_AutoML_20181212_105540_model_1            0.769752   0.572583                0.344331  0.442452  0.195764\n",
    "# GBM_grid_1_AutoML_20181212_105540_model_2            0.754366   0.918567                0.355855  0.496638  0.246649\n",
    "# DRF_1_AutoML_20181212_105540                         0.742892   0.595883                0.355403  0.452774  0.205004\n",
    "# XRT_1_AutoML_20181212_105540                         0.742091   0.599346                0.356583  0.453117  0.205315\n",
    "# DeepLearning_grid_1_AutoML_20181212_105540_model_2   0.741795   0.601497                0.368291  0.454904  0.206937\n",
    "# XGBoost_grid_1_AutoML_20181212_105540_model_1        0.693554   0.620702                0.40588   0.465791  0.216961\n",
    "# DeepLearning_1_AutoML_20181212_105540                0.69137    0.637954                0.409351  0.47178   0.222576\n",
    "# DeepLearning_grid_1_AutoML_20181212_105540_model_1   0.690084   0.661794                0.418469  0.476635  0.227181\n",
    "# GLM_grid_1_AutoML_20181212_105540_model_1            0.682648   0.63852                 0.397234  0.472683  0.223429\n",
    "#\n",
    "# [22 rows x 6 columns]\n",
    "\n",
    "# The leader model is stored here\n",
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = aml.predict(testH2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Playing with Amoxicillin - Clavulanic acid as regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T14:59:38.996890Z",
     "start_time": "2021-07-17T14:59:38.988890Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = filtered_data[features]\n",
    "y = filtered_data[best_label+'_filtered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:05:33.203150Z",
     "start_time": "2021-07-17T15:05:33.200150Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:05:34.243209Z",
     "start_time": "2021-07-17T15:05:33.736180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tot_actuals = []\n",
    "tot_predictions = []\n",
    "tot_rounded_predictions = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    xgb_model = xgb.XGBRegressor(n_jobs=1, tree_method='gpu_hist', gpu_id=0).fit(X.iloc[train_index], y.iloc[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    rounded_predictions = [min(final_dict.values(), key=lambda x:abs(x-pred)) for pred in predictions]\n",
    "    print(\"rounded: \", rounded_predictions)\n",
    "    print(\"actual: \", actuals.T[0])\n",
    "    print(mean_squared_error(actuals, predictions))\n",
    "    print(confusion_matrix([str(x) for x in actuals.T[0]], [str(x) for x in rounded_predictions]))\n",
    "    tot_actuals += list(actuals.T[0])\n",
    "    tot_rounded_predictions += rounded_predictions\n",
    "    tot_predictions += list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:05:42.620688Z",
     "start_time": "2021-07-17T15:05:42.611688Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(mean_squared_error(tot_actuals, tot_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:05:43.606745Z",
     "start_time": "2021-07-17T15:05:43.488738Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(\n",
    "    [str(x) for x in tot_actuals], \n",
    "    [str(x) for x in tot_rounded_predictions], \n",
    "    labels=[str(x) for x in final_dict.values()],\n",
    ")\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=[str(x) for x in final_dict.keys()],\n",
    ")\n",
    "disp.plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### run Parameter Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:35:09.177730Z",
     "start_time": "2021-07-17T15:35:09.173729Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth':[3, 4, 6, 8, 10], \n",
    "    'n_estimators': [20, 50, 100, 200],\n",
    "    'eta': uniform(loc=0, scale=1),\n",
    "    'gamma': uniform(loc=0, scale=100),\n",
    "    'min_child_weight': uniform(loc=0, scale=10),\n",
    "    ''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:35:09.469746Z",
     "start_time": "2021-07-17T15:35:09.455746Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(n_jobs=1, tree_method='gpu_hist', gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:35:09.748762Z",
     "start_time": "2021-07-17T15:35:09.743762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:35:10.059780Z",
     "start_time": "2021-07-17T15:35:10.048780Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(xgb_model, param_distributions=param_grid, random_state=rng, cv = kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:35:16.232133Z",
     "start_time": "2021-07-17T15:35:10.537808Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search = clf.fit(X, y)\n",
    "search.best_params_\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:35:16.681159Z",
     "start_time": "2021-07-17T15:35:16.239134Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tot_actuals = []\n",
    "tot_predictions = []\n",
    "tot_rounded_predictions = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    xgb_model = xgb.XGBRegressor(n_jobs=1, **search.best_params_).fit(X[train_index], y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    rounded_predictions = [min(final_dict.values(), key=lambda x:abs(x-pred)) for pred in predictions]\n",
    "    tot_actuals += list(actuals.T[0])\n",
    "    tot_rounded_predictions += rounded_predictions\n",
    "    tot_predictions += list(predictions)\n",
    "    \n",
    "print(mean_squared_error(tot_actuals, tot_predictions))\n",
    "cm = confusion_matrix(\n",
    "    [str(x) for x in tot_actuals], \n",
    "    [str(x) for x in tot_rounded_predictions], \n",
    "    labels=[str(x) for x in final_dict.values()],\n",
    ")\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=[str(x) for x in final_dict.keys()],\n",
    ")\n",
    "disp.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T15:33:54.611465Z",
     "start_time": "2021-07-17T15:33:54.604464Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
